models:
  dummy-7b:
    type: gguf
    path: ~/models/dummy_model.gguf
    n_threads: 11
    n_gpu_layers: 18
  dummy-openai:
    type: openai
    base_url: "http://dummy/url"
  dummy-ollama:
    type: ollama
    host: "http://localhost:112233"

profiles:
  precise:
    temperature: 0.7
    repeat_penalty: 1.176
    top_k: 40
    top_p: 0.1
  creative:
    temperature: 0.72
    repeat_penalty: 1.1
    top_k: 0
    top_p: 0.73
  sphinx:
    temperature: 1.99
    repeat_penalty: 1.15
    top_k: 30
    top_p: 0.18

chat:
  model: dummy-7b
  profile: precise
task:
  model: dummy-openai
  profile: precise
